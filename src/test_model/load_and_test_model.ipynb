{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23f68ae4",
   "metadata": {},
   "source": [
    "# Load and Test Model for test set "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccd236b",
   "metadata": {},
   "source": [
    "## Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c81e8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import av\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f77e221",
   "metadata": {},
   "source": [
    "## Init file paths and dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07bb4a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"dataset\"\n",
    "test_dir = f'../../{data_dir}/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b1b0841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All labels\n",
    "filtered_data = \"data\"\n",
    "test_label_df = pd.read_csv(f'../../{filtered_data}/test.csv', header=None)\n",
    "\n",
    "# convert all into hashmap - key = u_vid_name , value = label\n",
    "test_label = {f\"../../{test_dir}/{k[0]}\": k[1] for k in test_label_df.values.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "940d649b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique label: 10\n"
     ]
    }
   ],
   "source": [
    "# Total label + turkish to english translation\n",
    "total_label = pd.read_csv(f'../../{filtered_data}/filtered_ClassId.csv')\n",
    "u_len_label = len(total_label['ClassId'].unique())\n",
    "print(\"total unique label:\", u_len_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e603bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id_to_label = {k[0]: k[2] for k in total_label.values.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9b5ec02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'champion', 1: 'glass', 2: 'wrong', 3: 'bad', 4: 'married', 5: 'potato', 6: 'congratulations', 7: 'child', 8: 'inform', 9: 'father'}\n"
     ]
    }
   ],
   "source": [
    "print(class_id_to_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e80dc5e",
   "metadata": {},
   "source": [
    "## Load and process video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa309e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(vid_path, frames_cap, transforms=None):\n",
    "    \"\"\"Extract and transform video frames\n",
    "\n",
    "    Parameters:\n",
    "    vid_path (str): path to video file\n",
    "    frames_cap (int): number of frames to extract, evenly spaced\n",
    "    transforms (torchvision.transforms, optional): transformations to apply to frame\n",
    "\n",
    "    Returns:\n",
    "    list of numpy.array: vid_arr\n",
    "\n",
    "    \"\"\"\n",
    "    vid_arr = []\n",
    "    with av.open(vid_path) as container:\n",
    "        stream = container.streams.video[0]\n",
    "        n_frames = stream.frames\n",
    "        remainder = n_frames % frames_cap\n",
    "        interval = n_frames // frames_cap\n",
    "        take_frame_idx = 0\n",
    "        for frame_no, frame in enumerate(container.decode(stream)):\n",
    "            if frame_no == take_frame_idx:\n",
    "                img = frame.to_image()\n",
    "                if transforms:\n",
    "                    img = transforms(img)\n",
    "                vid_arr.append(np.array(img))\n",
    "                if remainder > 0:\n",
    "                    take_frame_idx += 1\n",
    "                    remainder -= 1\n",
    "                take_frame_idx += interval\n",
    "    if len(vid_arr) < frames_cap:\n",
    "        raise ValueError(f\"video with path '{vid_path}' is too short, please make sure that video has >={frames_cap} frames\")\n",
    "    return vid_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42e3645",
   "metadata": {},
   "source": [
    "## Load and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bff3d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73935aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_LSTM(\n",
       "  (encoder): CNN_Encoder(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (layers): Sequential(\n",
       "      (0): ConvBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (batchnorm2): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (a_fn): ReLU()\n",
       "        (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): ConvBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (batchnorm1): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (batchnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (a_fn): ReLU()\n",
       "        (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (2): ConvBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (batchnorm1): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (batchnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (a_fn): ReLU()\n",
       "      )\n",
       "      (3): ConvBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (batchnorm1): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (a_fn): ReLU()\n",
       "        (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (4): ConvBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (batchnorm1): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (a_fn): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (conv2): ConvBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (batchnorm1): BatchNorm2d(512, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (batchnorm2): BatchNorm2d(512, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (a_fn): ReLU()\n",
       "      (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    )\n",
       "    (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (decoder): LSTM_Decoder(\n",
       "    (lstm): LSTM(512, 512, batch_first=True, bidirectional=True)\n",
       "    (fc1): Linear(in_features=1024, out_features=10, bias=True)\n",
       "    (a_fn): ReLU()\n",
       "    (attention_layer): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.8, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import CNN_LSTM\n",
    "model = CNN_LSTM(10, \n",
    "                 latent_size=512, \n",
    "                 n_cnn_layers=6, \n",
    "                 n_rnn_layers=1, \n",
    "                 n_rnn_hidden_dim=512, \n",
    "                 cnn_bn=True, \n",
    "                 bidirectional=True, \n",
    "                 dropout_rate=0.8,\n",
    "                 device=\"cpu\",\n",
    "                 attention=True)\n",
    "checkpoint = torch.load(\"../../models/8-checkpoint.pt\", map_location=torch.device(\"cpu\"))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ccdc136",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_compose = transforms.Compose([transforms.Resize(256), \n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.5], std=[0.5])])\n",
    "test_dir = f'../../{data_dir}/test'\n",
    "def load_and_test_image(vid_name):\n",
    "    vid_color_path = f\"{test_dir}/{vid_name}_color.mp4\"\n",
    "    rgb_arr = extract_frames(vid_color_path, 30, transforms=transforms_compose)\n",
    "    vid_arr = np.array(rgb_arr)\n",
    "    vid_arr = vid_arr/255\n",
    "    vid_arr = torch.from_numpy(vid_arr).float()\n",
    "    vid_arr = vid_arr.unsqueeze(0)\n",
    "    predict_id = model.forward(vid_arr)\n",
    "    predict_id = predict_id.argmax(1).item()\n",
    "    real_id = test_label[f\"../../{test_dir}/{vid_name}\"]\n",
    "    return predict_id, class_id_to_label[predict_id], real_id, class_id_to_label[real_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9abd302d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 164/164 [07:22<00:00,  2.70s/it]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/test.csv\", names=[\"video_name\", \"class_id\"])\n",
    "predict_ids = []\n",
    "predict_labels = []\n",
    "real_ids = []\n",
    "real_labels = []\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    predict_id, predict_label, real_id, real_label = load_and_test_image(row['video_name'])\n",
    "    predict_ids.append(predict_id)\n",
    "    predict_labels.append(predict_label)\n",
    "    real_ids.append(real_id)\n",
    "    real_labels.append(real_label)\n",
    "\n",
    "df['predict_id'] = predict_ids\n",
    "df['predict_label'] = predict_labels\n",
    "df['real_id'] = real_ids\n",
    "df['real_label'] = real_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b756606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>class_id</th>\n",
       "      <th>predict_id</th>\n",
       "      <th>predict_label</th>\n",
       "      <th>real_id</th>\n",
       "      <th>real_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>signer34_sample4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>champion</td>\n",
       "      <td>0</td>\n",
       "      <td>champion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>signer34_sample43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>wrong</td>\n",
       "      <td>2</td>\n",
       "      <td>wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>signer34_sample130</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>champion</td>\n",
       "      <td>8</td>\n",
       "      <td>inform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>signer34_sample145</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>married</td>\n",
       "      <td>4</td>\n",
       "      <td>married</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>signer34_sample170</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>bad</td>\n",
       "      <td>7</td>\n",
       "      <td>child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>signer30_sample575</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>congratulations</td>\n",
       "      <td>3</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>signer30_sample576</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>potato</td>\n",
       "      <td>4</td>\n",
       "      <td>married</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>signer30_sample588</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>potato</td>\n",
       "      <td>6</td>\n",
       "      <td>congratulations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>signer30_sample617</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>potato</td>\n",
       "      <td>6</td>\n",
       "      <td>congratulations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>signer30_sample623</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>congratulations</td>\n",
       "      <td>3</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             video_name  class_id  predict_id    predict_label  real_id  \\\n",
       "0      signer34_sample4         0           0         champion        0   \n",
       "1     signer34_sample43         2           2            wrong        2   \n",
       "2    signer34_sample130         8           0         champion        8   \n",
       "3    signer34_sample145         4           4          married        4   \n",
       "4    signer34_sample170         7           3              bad        7   \n",
       "..                  ...       ...         ...              ...      ...   \n",
       "159  signer30_sample575         3           6  congratulations        3   \n",
       "160  signer30_sample576         4           5           potato        4   \n",
       "161  signer30_sample588         6           5           potato        6   \n",
       "162  signer30_sample617         6           5           potato        6   \n",
       "163  signer30_sample623         3           6  congratulations        3   \n",
       "\n",
       "          real_label  \n",
       "0           champion  \n",
       "1              wrong  \n",
       "2             inform  \n",
       "3            married  \n",
       "4              child  \n",
       "..               ...  \n",
       "159              bad  \n",
       "160          married  \n",
       "161  congratulations  \n",
       "162  congratulations  \n",
       "163              bad  \n",
       "\n",
       "[164 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
